{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRACTICAL 1 (WEEK 6): Introduction to R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the end of this practical you should be able to:\n",
    "* Open, modify and save R data files\n",
    "* View a dataset that is opened with R\n",
    "* Select particular rows for analysis\n",
    "* Produce descriptive statistics using R\n",
    "* Produce plots (charts) using R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R Statistical Analysis Software\n",
    "\n",
    "R is a programming language and free software environment for statistical computing and graphics supported by the R Foundation for Statistical Computing. The R language is widely used among statisticians and data miners for developing statistical software and data analysis. R allows you to store, trans-form and analyse data and produce charts and tables. \n",
    "\n",
    "There is one main difference between R and programs like Excel or other spreadsheet packages and that is that it doesn't use menus or a what we call a \"Graphical User Interface\" (or GUI). If you think back to fundamental methods, all of the practicals you did were in Excel where you would click through a series of menus to complete the task. This is fine for analyses that are simple with only a few steps, but when we get to more advanced and complex analyses with multiple steps we need a different approach. This is where R comes in. Unlike with Excel, our interaction with R is through programming or coding where we write a series of commands that are sent to the R software for execution. So, instead of a series of menus that we click on, with R we have to write out our commands and save them in what are called \"scripts\". These scripts are just documents with collections of R programming commands. This has a huge advantage when we come to do our analysis because these scripts essentially contain an entire record of the various steps that you take. This is really useful if we want to change anything in our analysis or if we make a mistake early on because rather than having to re-click all of those menus, with a script, we can just go back to the part we want to change and then re-run the script to reproduce our analysis. This is the basis for modern statistical analysis in academic research; writing analysis scripts that are reproducible and efficient. These programming skills are widely used in many professional careers and are hugely sought after by many employers! \n",
    "\n",
    "In the practicals over the next few weeks we are going to introduce you to the basics of programming in R. We will help you work through using a variety of statistical tests and methods in and how to write ocmmands to carry them out using the R software. \n",
    "\n",
    "## Jupyter Notebooks\n",
    "\n",
    "To do this we will be using what are known as \"Jupyter notebooks\" such as this one. Jupyter notebooks are great learning tools because they are essentially a combination of textbooks and software. They allow you to write and execute code \"live\" alongside text/images that explain what is going on (rather than for example a separate word document with instructions). Each week, you will have a new notebook and a new dataset to work with Demonstrators will be available to help in each online practical session. If you require assistance at any time, just alert the demonstrators who will assist you as soon as they can.\n",
    "\n",
    "Some of the following exercises are intended to help you in learning how to use R and will inevitably seem like you are just following instructions. It would be easy to do this without thinking – if you push the right buttons you will get the “right” answers. However, for your formative and summative assessments, you will not receive such close guidance – these practicals are to prepare you for this! The exercises in this practical will involve you typing out (or copying and pasting if you prefer!) commands as directed into empty code cells and executing these commands. As you do this, try to think about what is going on behind the scenes at all times. What are the results telling you? Are they significant? Why did you run a particular test? What does the test mean? Is it the correct test? Thinking about it like this will help you enormously on the assessment, and if you choose to include any kind of quantitative analysis in your dissertation. There are many manuals and textbooks that can provide guidance on statistics, but they cannot tell you what to do when you are working with your own data; you will have to decide which tests to use with what data and how to interpret the results. This is what we will be testing in the assessment. Throughout the practical there will also be exercises where you will have to think about the code you need. This should help you develop these skills on your own. The answers to these exercises can be found at the end of the notebook if you get really stuck but do try on your own first or ask a demonstrator for help as this will help you learn much more effectively. Feel free to work in groups if this is helpful as well!\n",
    "\n",
    "## Preparation\n",
    "\n",
    "If you look in the noteable files area, in the folder where you found this notebook, you should see a file called \"FloridaSalaries.csv\". This is the datafile we are going to be working with for this practical. It consists of a data file containing data on starting salaries for graduates from the University of Florida. Each row of data in the file contains information about an individual graduate including:\n",
    "\n",
    "* Sex\n",
    "* The college they graduated from\n",
    "* Salary\n",
    "* Type of degree\n",
    "* Date of graduation\n",
    "\n",
    "### Packages\n",
    "Before we get started, the first thing we need to do is import some packages to our R session. These packages are part of the built-in functionality in python. What are packages? R works through the use of a whole bunch of \"add-on\" packages which can be thought of as different pieces of software. Because of this, we need to actually import these packages each time we start a new R session. R has loads of these \"built-in\" packages. To import these packages we use the command `library()` and put the name of the package we need in the brackets. \n",
    "\n",
    "Type out or copy the following code in the code cell below and then click the `run` button (note it may take a little while so be patient!).\n",
    "\n",
    "`library(tidyverse)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Loading data\n",
    "\n",
    "So the first part of any data analysis is to load the data into R. This is much like clicking on \"file\" -> \"open\" in excel, in other words the process by which the data is loaded into the software. But here we will type out the command to load the data. \n",
    "The first task we have is to read in all of our datasets into memory so we can access them and work with them. \n",
    "By default R notebook looks for files in the same folder as the notebook is saved. To list all the files in the current directory we can run the code `list.files()`. \n",
    "\n",
    "Type out or copy the following code in the code cell below and then click the `run` button (press shift+enter).\n",
    "\n",
    "`\n",
    "list.files()\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here in the list of files we can see the datafile that we are going to use, `FloridaSalaries.csv`. You will notice that the file extension is `.csv`. this stands for \"comma separated values\". This is basically a text file data format with each piece of data separated by a comma symbol. If you like, you can click on the file in the files area to see what it contains. You will be able to see rows of information separated by commas. In order to load the data, we need to tell R that it is a `csv` file. We do this using the command `read_csv()` with the filename in the brackets.\n",
    "\n",
    "You will also notice in the code below that there is a funny symbol - `<-` made up of a `<` and `-` symbols. This is called an assignment operator and is very commonly used in R programming. What it does is put the result of the `read_csv` command into an object or thing called `data`. We could name this anything we like, it is simply a placeholder for the object that holds our newly loaded dataset. This means that whenever we want to do something with that dataset we have a convenient name that we can use to refer to this dataset.\n",
    "\n",
    "Run the following code in the cell below to read the data (when it is complete you will see a red box with some text, dont't worry this is correct!)\n",
    "\n",
    "`data <- read_csv(\"FloridaSalaries.csv\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often helpful to view our data. We can do this simply by just typing the name we have given our data and executing this. Do this in the cell below.\n",
    "\n",
    "Hint: all we need to do here is type the name of the data we have assigned above so just type:\n",
    "\n",
    "`data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a spreadsheet view of the data.\n",
    "\n",
    "R can also hold multiple datasets in memory at the same time which can be helpful. Run the code below, which reads the same dataset but with a different name this time i.e. `DuplicateData`. In thie case the data is exactly same but R is simply holding it in memory with a different name. Have a think why having two diferent datasets available at the same time might be useful...\n",
    "\n",
    "`DuplicateData <- read_csv(\"FloridaSalaries.csv\")\n",
    "DuplicateData`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Exercise 1</b> \n",
    "    \n",
    "<b>Instead of calling our object `data` or `DuplicateData`, we want to call it something more meaningful, like `FloridaSalaries`. Copy and then edit the code below in the cell below so that the data is placed into an object called `FloridaSalaries`. HINT: Look at the code in the previous cells to see how to do this. Ask a demonstrator if you get stuck! You need to make sure it is named correctly for the rest of this practical to work!\n",
    "\n",
    "When you have correctly edited the code, execute it so we have the correctly named data object in memory. Then in the next cell view the new dataset object that you have created</b>\n",
    "\n",
    "`<- read_csv(\"FloridaSalaries.csv\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FloridaSalaries <- read_csv(\"FloridaSalaries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Taking a first look at the data\n",
    "\n",
    "If everything worked ok and you completed the exercise correctly this should run with no errors and should display the data. You can also check that the data has loaded with the `head` command which basically presents the first few rows of your dataset. Use the code below to do this...\n",
    "\n",
    "`head(FloridaSalaries)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to see more rows of data you can add `n=100` to the command to see the first 100 rows of data. Like this:\n",
    "\n",
    "`head(FloridaSalaries, n=100)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check what we call the dimensions of the dataset. In other words how many columns and how many rows it has. We do this using the dimension command, or `dim` for short. this is useful if we have very large datasets perhaps thousands or even millions of rows/columns for example.\n",
    "\n",
    "`dim(FloridaSalaries)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be able to see in the output that the data has 1100 rows and 6 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Manipulating data\n",
    "\n",
    "If you look at the column labelled `graddate` you can see that it contains a series of 1's. If we were to look at the whole dataset we would see other numbers as well. These different values correspond to different dates according to the following labels:\n",
    "\n",
    "- 1 = Autumn 1989\n",
    "- 2 = Spring 1990\n",
    "- 3 = Autumn 1990\n",
    "- 4 = Spring 1991\n",
    "\n",
    "If you think back to Fundamental Methods in Geography, where you learned about different types of variables, this is what we call a *categorical variable*. The number values are called the *codes* and the text is known as the *value labels*. In order to conduct our analysis correctly, R needs to be told what data type each variable is. If you look at the top of the data, underneath each column name, you will some text between `<>` symbols e.g. `<dbl>` or `<chr>`. These tell us what R currently thinks each variable is. Each of these means the following:\n",
    "\n",
    "* `dbl` - This stands for `double` and represents a continuous variable with numeric information\n",
    "* `chr` - This stands for `character` which means the variable contains text information (also known as strings).\n",
    "* `fct` - this stands for `factor` which means the information is categorical with each value representing a different category.\n",
    "\n",
    "There are a number of other types of data but these are the most important ones. You will also notice that currently the `graddate` variable is labelled as a `dbl` when it should be a `fct`. We will change this next with the `factor()` command which takes a variable and turns it into a factor. Let's do this running the following code in the code cell below:\n",
    "\n",
    "`FloridaSalaries$new_graddate <- factor(FloridaSalaries$graddate)`\n",
    "\n",
    "This wont output anything on its own but run the code and then we will break down the command bit by bit to explain what is going on. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FloridaSalaries$new_graddate <- factor(FloridaSalaries$graddate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the `factor(FloridaSalaries$graddate)` bit ... what exactly does `FloridaSalaries$graddate` mean? Well, this is important because it is how we select particular variables from particular datasets through use of the `$` symbol. In other words what this is saying is <b>select the graddate variable from the FloridaSalaries dataset</b> and then do something with it i.e. in this case turn it into a factor variable. \n",
    "\n",
    "<b>IMPORTANT INFORMATION ALERT!</b> If ever you want to perform an action on a particular variable from a particular dataset you use the `dataset name$variable name` convention.\n",
    "\n",
    "Now for the next part, the `FloridaSalaries$new_graddate <-` bit on the left of the command. This part is basically saying take output from the code to the right of `<-` and <b>assign</b> it to a <b>new</b> variable called `new_graddate` in the `FloridaSalaries` dataset. Remember, `<-` basically means assign (as we discussed earlier)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, take a look at the data again in the code cell below (remember we do this by typing the name of the data `FloridaSalaries`). We should see a new variable `new_graddate` has been added next to the old variable `graddate`. You should also notice that this is the same as the old variable but this time is type `<fct>` rather than type `<dbl>`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FloridaSalaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to <b>replace</b> the old variable (instead of creating a new one) we would do the following instead:\n",
    "\n",
    "`FloridaSalaries$graddate <- factor(FloridaSalaries$graddate)`\n",
    "\n",
    "Notice on the left-hand side we use `graddate` i.e. the same name as the existing variable which means it will overwrite. If you want, you can execute this code below so you can see for yourself the difference between creating new variables and overwriting existing ones. In general however, it is best practice to avoid overwriting existing variables in case you make a mistake or want to go back to the original variable for whatever reason. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! But now, we also need to change the labels as well, so that they are more meaningful. At the moment, they just read 1, 2 etc which isnt very helpful. It would be better if they were labeled with the actual value labels (e.g. \"Autumn 1990\" etc) To change categorical variable labels we use the `fct_recode()` command, which just means \"factor recode\". We do this using the code below:\n",
    "\n",
    "`FloridaSalaries$new_graddate <- fct_recode(FloridaSalaries$new_graddate, \n",
    "                                       \"Autumn 1989\" = \"1\", \n",
    "                                       \"Spring 1990\" = \"2\",\n",
    "                                       \"Autumn 1990\" = \"3\",\n",
    "                                       \"Spring 1991\" = \"4\")`\n",
    "                                       \n",
    "To make this code more readable, I have arranged the lines slightly differently but dont worry it still works the same (just copy the whole thing and paste into the cell). This code may look complicated but if you look at it carefully it is very similar to the code we worked through above. This time though we include the list of labels we want to add. Notice how the label we want to add comes first, followed by `=` and then the value the label applies to. Also note the use of `\"` when specifying the labels. This just tells R that we are working with text information. Run the code in the cell below and then examine the data in the usual way to see that it has added the labels. You should be able to see that the `graddate` variable now includes informative labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FloridaSalaries$new_graddate <- fct_recode(FloridaSalaries$new_graddate, \n",
    "                                       \"Autumn 1989\" = \"1\", \n",
    "                                       \"Spring 1990\" = \"2\",\n",
    "                                       \"Autumn 1990\" = \"3\",\n",
    "                                       \"Spring 1991\" = \"4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FloridaSalaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Exercise 2</b> \n",
    "    \n",
    "<b>There are two other variables that need to be converted to factor variables, `sex` and `college`. At the moment they are character variables but they would be better as factor variables because that way we can produce summary statistics for them later on. Have a go at creating new versions of these variables as factors. You dont need to relabel them as the labels are already there in the variable.\n",
    "\n",
    "HINT: You will need to use the `factor()` command as we did a few cells further up... Remember to ask a demonstrator if you get stuck!</b>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, we also need to create new or modified versions of variables. In R we do this with the `mutate` command. Lets say we wanted to convert the salary variable  into units of thousands of dollars (rather than single dollars). In other words, we want a new variable which contains the salary value divided by 1000. The code below does this for us:\n",
    "\n",
    "`FloridaSalaries <- mutate(FloridaSalaries, salary_thousands = salary/1000)`\n",
    "\n",
    "This code produces a new variable called salary_thousands and then updates the existing `FloridaSalaries` dataset with this new variable. All of the standard math symbols work here just like in Excel so you could use `+ - /` to add, subtract and divide respectively in your calculations. \n",
    "\n",
    "Run the code above in the cell below. Dont forget to add `FloridaSalaries` in the second cell to view the result! You should be able to see a new column added to the data containing the new variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Exercise 3</b> \n",
    "    \n",
    "<b>Lets say we want to convert the salaries data into British pounds and store this in a new variable. Assuming the exchange rate is <b><i>1.4 US dollars to 1 British pound</b></i>, edit the code from the previous cell to create a new variable called `salary_pounds`. Remember, look closely at the code above to see if you can figure what you need to change! Execute this code in the cell below...</b>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we want to focus our analysis on subgroups within our main data. R allows us to create new data sets that contain specific subgroups of our data (e.g. female engineers) – these are called subsets. We will do so now using the `filter()` command.\n",
    "\n",
    "Let’s say we want to create a new dataset that contains information for only female graduates. The code below does this for us:\n",
    "\n",
    "`SalariesFemale <- filter(FloridaSalaries, sex == \"F\")`\n",
    "\n",
    "This code looks very similar to the mutate command. This time we are creating a <b>new</b> dataset called `SalariesFemale`. On the right hand side of the command we first speciy which dataset we want to work with (i.e. `FloridaSalaries`) and then specify the actual subset expression (i.e. the `sex == \"F\"` part) which includes the variable we want to filter and the value of that variable to use as the actual filter. Also note that in the subset expression the ‘F’ is in double quotes – as it must be when the variable is categorical – and that 2 equal signs have been used. When we test if values are equal in R, we must use 2 equals signs.\n",
    "\n",
    "Use the next few cells to run this code and also take a look at the new dataset we have created. You should see that it now only contains information for the women in the dataset. Remember to also use the `dim()` command as well to look at the dimensions of the new data. The number of rows shoulds be much less than the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use much more complex expressins to filter our data incuding using more than one variable and other operators. For example, let's say we were interested in individuals earning more than $30,000 and who graduated from the college of engineering. We would do this similarly, but the expression will need to be 2 expressions, separated by a `&` symbol, i.e. like:\n",
    "\n",
    "<b>college==\"Engineering\" & salary > 30000</b>\n",
    "\n",
    "This means that we want data where the college is ‘Engineering’ AND the salary is over 30K. The “&” implies the “AND” – if we wanted EITHER engineers OR graduates with salaries over 30K, the “&” would be replaced by “|” (the Shift + “\\” key). Putting all of this together into the complete command would look like:\n",
    "\n",
    "`SalariesEng30k <- filter(FloridaSalaries, college==\"Engineering\" & salary > 30000)`\n",
    "\n",
    "Note the new name we have given for the new subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "    \n",
    "Can you figure out how to create a subset of *all the female engineers*? Write the code in the cell below making sure to give the dataset an appropriate name. Hint: Remember to look closely at the code above to see what you need to change to create this new dataset</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now getting to the stage where we have created a lot of new datasets and it can be easy to lose track of all of them. A useful commmand in R is `objects()`. Running this provides a list of the current data objects that R has in memory. This is useful if you working with lots of different datasets. Sometimes there are datasets that we no longer need. We can use the `rm()` (stands for \"remove\") command to delete these. Try out both in the cells below to test them out. \n",
    "\n",
    "<b>Note: `objects()` can be run with nothing in the brackets but `rm()` needs to include the dataset you wish to remove e.g. `rm(DuplicateData)` or `rm(data)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Describing data\n",
    "\n",
    "Again, thinking back to fundamental methods in geography, you wil lremember all of the different ways of describing data. We will now move on to calculating these in R (which is much easier and more efficient in R than in Excel!).\n",
    "\n",
    "A really easy way to calculate a whole bunch of different summary statistics in R is to use the `summary()` command. All we have to do is put the name of the dataset in the brackets. e.g. \n",
    "\n",
    "`summary(FloridaSalaries)`\n",
    "\n",
    "Run this code below to see what it produces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get individual variables for mean and strandard deviation using `mean()` and `sd()`.\n",
    "\n",
    "Run these two piece of code below:\n",
    "\n",
    "`mean(FloridaSalaries$salary)`\n",
    "\n",
    "`sd(FloridaSalaries$salary)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time, we also want to see descriptive statistics broken down by different groups. We can do that with the `tapply()` command. The input for the tapply( ) function is 1) the variable we want to be described, 2) the categorical variable that defines the groups, and 3) the function to be applied to the outcome variable (e.g. mean or standard deviation). You can see this below. Run this code to see the result. \n",
    "\n",
    "`tapply(FloridaSalaries$salary,FloridaSalaries$sex, mean)`\n",
    "\n",
    "`tapply(FloridaSalaries$salary,FloridaSalaries$sex, sd)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Exercise 5</b> \n",
    "    \n",
    "<b>In the cell below, write and execute code to answer the following: \n",
    "* A: What is the average salary among graduates from the \"Fine Arts\" College? \n",
    "* B: Which college has the highest average salary? </b>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Graphing data\n",
    "\n",
    "Perhaps the most powerful way of describing data is to produce visualisations and graphs. R is very flexible in its abillity to produce graphs. Let's start with a boxplot. You have seen Box plots of data before in Lecture and in Fundamental Methods.\n",
    "\n",
    "We can produce boxplots for single variables really easily using the `boxplot()` command. Below will produce a boxplot of our salary variable.\n",
    "\n",
    "`boxplot(FloridaSalaries$salary)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that it has no labels, titles or anything. We can add these easily with the below code. It should be easy to see what is going on here. `main` allows us to provide a title and `ylab` a title for the y-axis. Run this code below.\n",
    "\n",
    "`boxplot(FloridaSalaries$salary, main=\"Salary of Graduates from the University of Florida\", ylab=\"Salary($)\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, often we are interested in boxpolots broken down by categories of other variables i.e. as we did for the means and standard deviations earlier on. The code below does this: \n",
    "\n",
    "`boxplot(salary~sex, data=FloridaSalaries, main=\"Salary of Graduates from the University of Florida\", ylab=\"Salary($)\")`\n",
    "\n",
    "The code for this is a little different so let's break it down. In the brackets, the first thing you will notice is the two variables separated by the `~` symbol. the first of these variables ins the one we wish to show on the boxplot (e.g. salary) and the second is the categorical variable we wish to break it down by (e.g. sex). The second part (e.g. `data=FloridaSalaries`) is the dataset we want to pull the variables from. The rest is the same as before. Run this code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that now we have an additional variable on the x-axis (sex). R has labelled this automatically but we need to improve it e.g. by capitalising the first word. We can do this by adding `xlab` just like with the y label.\n",
    "\n",
    "`boxplot(salary~sex, data=FloridaSalaries, \n",
    "                main=\"Salary of Graduates from the University of Florida\", \n",
    "                ylab=\"Salary($)\", \n",
    "                xlab = \"Sex\")`\n",
    "                \n",
    "Run this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most common plots that you will are histograms for continuous data as these give us an idea of the distribution of the data. this is a really important concept that we will be revisiting more in the next few weeks. But for now, we need to know how to produce a histogram. The code to do this is much the same as for boxplots, but instead we use the `hist()` command. but, all of the commands we used for the main title and x and y labels is the same e.g.:\n",
    "\n",
    "`hist(FloridaSalaries$salary, main = \"Salary Histogram\", ylab=\"Salary($)\", xlab=\"Frequency\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Exercise 6</b> \n",
    "    \n",
    "<b>Using the female-only subset of data that we created earlier (you may need to check further up to remember what you called this!), produce a new salary histogram showing the distribution of female only salaries</b>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is the end of this practical. See you next week!\n",
    "\n",
    "Note: answers to the exercises are below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Answers\n",
    "\n",
    "1. To create a dataset with the name FloridaSalaries, we assign (`<-`) the data from the file \"FloridaSalaries.csv\" with the command `read_csv()`. \n",
    "\n",
    "    Code: `FloridaSalaries <- read_csv(\"FloridaSalaries.csv\")`\n",
    "    \n",
    "    \n",
    "2. To create new factor variables new_college and new_sex from the existing variables college and sex, we use the command `factor()`. \n",
    "\n",
    "    Code:    `FloridaSalaries$new_college <- factor(FloridaSalaries$college)` and \n",
    "    `FloridaSalaries$new_sex <-factor(FloridaSalaries$sex)`\n",
    "\n",
    "    \n",
    "    \n",
    "3. To create a new variable salary_pounds from the variable salary, we divide by 1.4 using the command `mutate()`. \n",
    "\n",
    "    Code: `FloridaSalaries <- mutate(FloridaSalaries, salary_pounds = salary/1.4)`\n",
    "    \n",
    "    \n",
    "4. To create a new dataset of the salaries of female engineers, we filter the dataset using the command `filter()`, for the parameters `college == 'Engineering'` and `sex == 'F'`. \n",
    "\n",
    "    Code: `FemaleSalariesEngineering <- filter(FloridaSalaries, college==\"Engineering\" & sex == 'F')`\n",
    "    \n",
    "    \n",
    "5. To calculate the mean salary for each college, we use the command `tapply`, and filter the variable salary by the variable college. \n",
    "\n",
    "    Code: `tapply(FloridaSalaries$salary,FloridaSalaries$college, mean)`\n",
    "    \n",
    "    1. The average salary of the college of Fine Arts is $23450.\n",
    "    2. The degree with the highest mean salary is Engineering\n",
    "    \n",
    "    \n",
    "6. To create a histogram of the salaries of Female graduates, we use the command `hist()` on the dataset SalariesFemale and the variable salary. \n",
    "\n",
    "    Code: `hist(SalariesFemale$salary, main = \"Female Salary Histogram\", ylab=\"Female Salary($)\", xlab=\"Frequency\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
